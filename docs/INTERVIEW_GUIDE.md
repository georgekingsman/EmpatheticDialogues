# é¢è¯•é¡¹ç›®å±•ç¤ºæŒ‡å— | Interview Project Presentation Guide
## Empathetic Dialogue Evaluation Framework

> æœ¬æ–‡æ¡£ä¸ºç¾å›½å¤§å­¦é¢è¯•å‡†å¤‡ï¼ˆPhD / RA / MS é¢è¯•ï¼‰ï¼Œä¸­è‹±å¯¹ç…§ï¼Œå¸®åŠ©ä½ å…¨æ–¹ä½å±•ç¤ºé¡¹ç›®ã€‚  
> This guide is for US university interviews (PhD / RA / MS). Bilingual Chinese-English, covering all aspects of the project.
>
> å‚è€ƒå›ç­”ä¼˜å…ˆç»™å‡º **è‹±æ–‡ç‰ˆ**ï¼ˆé¢è¯•è¯­è¨€ï¼‰ï¼Œé™„ä¸­æ–‡æ³¨é‡Šå¸®åŠ©ç†è§£ã€‚  
> Suggested answers are given in **English first** (interview language), with Chinese notes for reference.

---

## ç›®å½• | Table of Contents

- [ä¸€ã€30 ç§’ç”µæ¢¯æ¼”è®² | 30-Second Elevator Pitch](#ä¸€30-ç§’ç”µæ¢¯æ¼”è®²--30-second-elevator-pitch)
- [äºŒã€3 åˆ†é’Ÿé¡¹ç›®æ¦‚è¿° | 3-Minute Project Overview](#äºŒ3-åˆ†é’Ÿé¡¹ç›®æ¦‚è¿°--3-minute-project-overview)
- [ä¸‰ã€æŠ€æœ¯æ·±æ½œ | Technical Deep Dive](#ä¸‰æŠ€æœ¯æ·±æ½œ--technical-deep-dive)
  - [3.1 æ•°æ®ç®¡çº¿ | Data Pipeline](#31-æ•°æ®ç®¡çº¿--data-pipeline)
  - [3.2 æ¨¡å‹æ¶æ„ | Model Architecture: Chain-of-Empathy](#32-æ¨¡å‹æ¶æ„--model-architecture-chain-of-empathy)
  - [3.3 LLM-as-a-Judge è¯„ä¼°ç®¡é“ | LLM Judge Pipeline](#33-llm-as-a-judge-è¯„ä¼°ç®¡é“--llm-judge-pipeline)
  - [3.4 ç»Ÿè®¡æ ¡å‡† | Statistical Calibration](#34-ç»Ÿè®¡æ ¡å‡†--statistical-calibration)
  - [3.5 æ¶ˆèå®éªŒ | Ablation Studies](#35-æ¶ˆèå®éªŒ--ablation-studies)
- [å››ã€å·¥ç¨‹èƒ½åŠ›å±•ç¤º | Engineering Skills to Highlight](#å››å·¥ç¨‹èƒ½åŠ›å±•ç¤º--engineering-skills-to-highlight)
- [äº”ã€ç ”ç©¶æ€ç»´å±•ç¤º | Research Thinking to Demonstrate](#äº”ç ”ç©¶æ€ç»´å±•ç¤º--research-thinking-to-demonstrate)
- [å…­ã€é¢è¯•é«˜é¢‘é—®é¢˜ | Frequently Asked Interview Questions](#å…­é¢è¯•é«˜é¢‘é—®é¢˜--frequently-asked-interview-questions)
- [ä¸ƒã€æ¼”ç¤º Demo æµç¨‹ | Demo Walkthrough](#ä¸ƒæ¼”ç¤º-demo-æµç¨‹--demo-walkthrough)
- [å…«ã€æŒ‰é¢è¯•åœºæ™¯è°ƒæ•´é‡å¿ƒ | Adjusting Focus by Interview Type](#å…«æŒ‰é¢è¯•åœºæ™¯è°ƒæ•´é‡å¿ƒ--adjusting-focus-by-interview-type)
- [ä¹ã€ç®€å† Bullet Points | Resume Bullet Points](#ä¹ç®€å†-bullet-points--resume-bullet-points)
- [é™„å½•ï¼šå…³é”®æ•°å­—é€ŸæŸ¥è¡¨ | Appendix: Key Numbers Cheat Sheet](#é™„å½•å…³é”®æ•°å­—é€ŸæŸ¥è¡¨--appendix-key-numbers-cheat-sheet)

---

## ä¸€ã€30 ç§’ç”µæ¢¯æ¼”è®² | 30-Second Elevator Pitch

> **èƒŒä¸‹æ¥è‹±æ–‡ç‰ˆï¼Œéšæ—¶èƒ½è®²ã€‚**  
> **Memorize the English version. Be ready to deliver it anytime.**

### English Version (é¢è¯•æ—¶è¯´è¿™ä¸ª)

"I built an evaluation framework for empathetic dialogue systems. The core question is: **how do you automatically and reliably measure whether an AI response is empathetic?** Traditional metrics like BLEU and ROUGE only measure lexical overlap â€” they can't capture empathy at all. And large-scale human annotation is expensive, slow, and hard to reproduce.

My approach is to design a **4-dimension scoring rubric**, use **LLM-as-a-Judge** for automated scoring, and then apply **statistical calibration** â€” specifically isotonic regression trained on public human-rated datasets â€” to align LLM scores with human judgments. The result: **MAE reduced by 31% to 63%**, while preserving rank correlation. The entire pipeline is fully reproducible at zero human annotation cost."

### ä¸­æ–‡ç‰ˆï¼ˆå¸®åŠ©ç†è§£é€»è¾‘ï¼‰

"æˆ‘åšäº†ä¸€ä¸ªå…±æƒ…å¯¹è¯è¯„ä¼°æ¡†æ¶ã€‚æ ¸å¿ƒé—®é¢˜ï¼šæ€ä¹ˆè‡ªåŠ¨ã€å¯é åœ°è¯„ä¼° AI å›å¤çš„å…±æƒ…è´¨é‡ï¼ŸBLEU/ROUGE åªè¡¡é‡è¯åŒ¹é…ï¼Œè¯„ä¸äº†å…±æƒ…ï¼›äººå·¥æ ‡æ³¨è´µã€æ…¢ã€ä¸å¯å¤ç°ã€‚æˆ‘çš„æ–¹æ¡ˆï¼šå››ç»´è¯„åˆ†é‡è¡¨ + LLM-as-a-Judge è‡ªåŠ¨æ‰“åˆ† + å…¬å¼€äººå·¥æ•°æ®é›†åš isotonic regression æ ¡å‡†ã€‚MAE é™äº† 31%-63%ï¼Œæ’åºä¸€è‡´æ€§ä¸å˜ï¼Œé›¶äººå·¥æ ‡æ³¨æˆæœ¬ã€‚"

---

## äºŒã€3 åˆ†é’Ÿé¡¹ç›®æ¦‚è¿° | 3-Minute Project Overview

> æŒ‰ **Problem â†’ Approach â†’ Implementation â†’ Results â†’ Contributions** çš„æ•…äº‹çº¿è®²ã€‚  
> Follow the **P-A-I-R-C** narrative arc.

### 1) Problem é—®é¢˜ï¼ˆ30sï¼‰

**English:**
"Evaluating empathy in dialogue is an open challenge. Reference-based metrics like BLEU and ROUGE measure surface-level word overlap, but empathy is a semantic property â€” two sentences can be equally empathetic with completely different wording. Human annotation is the gold standard, but it's costly, time-consuming, and suffers from low inter-annotator agreement. In my project, the Krippendorff's alpha between human annotators was actually negative, showing how difficult it is for humans to reliably rate empathy."

**ä¸­æ–‡è¦ç‚¹ï¼š**
- BLEU/ROUGE æ˜¯è¯åŒ¹é…ï¼Œè¡¡é‡ä¸äº†å…±æƒ…
- äººå·¥æ ‡æ³¨è´µ/æ…¢/ä¸€è‡´æ€§å·®ï¼ˆKrippendorff Î± ä¸ºè´Ÿå€¼ï¼‰
- è¿™æ˜¯ä¸€ä¸ªå¼€æ”¾æ€§ç ”ç©¶é—®é¢˜

### 2) Approach æ–¹æ¡ˆï¼ˆ30sï¼‰

**English:**
"My solution has three components:
1. A **4-dimension rubric** â€” emotion recognition, validation & warmth, helpfulness, and safety â€” on a 1-5 Likert scale with detailed anchor descriptions.
2. An **LLM-as-a-Judge pipeline** â€” I use DeepSeek Chat to score each response 3 times with structured JSON output, enabling multi-repeat stability analysis.
3. **External human-anchored calibration** â€” rather than collecting our own expensive annotations, I train a calibrator on publicly available human-rated datasets and transfer it to align our LLM judge scores with human judgments."

**ä¸­æ–‡è¦ç‚¹ï¼š**
- å››ç»´é‡è¡¨ï¼ˆæƒ…æ„Ÿè¯†åˆ« / éªŒè¯æ¸©æš– / å®ç”¨æ€§ / å®‰å…¨è¾¹ç•Œï¼‰Ã— 1-5 Likert
- LLM Judgeï¼ˆDeepSeek Chatï¼Œæ¯æ ·æœ¬ 3 æ¬¡ï¼Œç»“æ„åŒ– JSONï¼‰
- å¤–éƒ¨äººå·¥é”šå®šæ ¡å‡†ï¼ˆå…¬å¼€æ•°æ®é›†è®­ç»ƒæ ¡å‡†å™¨ â†’ è¿ç§»åˆ°è‡ªæœ‰æ¨¡å‹ï¼‰

### 3) Implementation å®ç°ï¼ˆ60sï¼‰

**English:**
"I trained 3 contrastive models on 5,318 mental health counseling dialogues from PsychCentral:
- **Vanilla GPT-2** as a lower bound â€” no fine-tuning at all.
- **Fine-tuned GPT-2** as a standard baseline.
- **GPT-2 + Chain-of-Empathy** â€” my custom architecture that adds a 5-stage empathy reasoning chain inspired by CBT cognitive processes, fused into GPT-2 via additive injection.

For evaluation, I executed **1,800 LLM API calls** â€” 200 test samples Ã— 3 models Ã— 3 repeats â€” with zero parsing failures. I then implemented two calibration routes: isotonic regression and ordinal logistic regression. I also ran ablation studies on repeat sensitivity and prompt variant robustness."

**ä¸­æ–‡è¦ç‚¹ï¼š**
- 5,318 æ¡å¿ƒç†å’¨è¯¢å¯¹è¯ï¼Œ3 ä¸ªå¯¹ç…§æ¨¡å‹
- Chain-of-Empathyï¼š5 é˜¶æ®µæ¨ç†é“¾ + åŠ æ€§èåˆ
- 1,800 æ¬¡ API è°ƒç”¨ï¼Œ0 é”™è¯¯
- åŒè·¯æ ¡å‡† + æ¶ˆèå®éªŒ

### 4) Results ç»“æœï¼ˆ30sï¼‰

**English:**

| Metric | Value |
|--------|-------|
| Judge self-consistency | Exact: 88-100%, Â±1: 96-100% |
| Calibration MAE reduction | 31.3% â€“ 62.8% (isotonic) |
| Post-calibration MAE range | 0.20 â€“ 0.29 (on a 1-5 scale) |
| Spearman rank correlation | Preserved after calibration (0.32 â€“ 0.79) |
| Optimal repeat count | k=1 sufficient (additional repeats: marginal gain < 0.01) |

"The key finding is that isotonic regression reduces MAE by over 50% on average, **while preserving rank correlation** â€” meaning the calibration corrects scale bias without hurting the judge's discriminative ability."

**ä¸­æ–‡è¦ç‚¹ï¼š**
- æ ¡å‡†å MAE é™ 31-63%ï¼Œæ’åºä¸å˜
- Judge æåº¦è‡ªæ´½ï¼ˆâ‰¥96% near agreementï¼‰
- k=1 å¤Ÿç”¨ â†’ å¯çœ 66% API æˆæœ¬

### 5) Contributions è´¡çŒ®ï¼ˆ30sï¼‰

**English:**
"Three contributions:
1. **Methodological**: I propose external human-anchored calibration â€” using public datasets as an unbiased anchor instead of collecting your own annotations.

å…¬å¼€æ•°æ®é›†ï¼ˆå·²æœ‰äººå·¥è¯„åˆ†ï¼‰
    â†“
åŒä¸€ä¸ª Judge ç»™å®ƒæ‰“åˆ†
    â†“
å¯¹æ¯”ï¼šJudge åˆ† vs äººå·¥åˆ† â†’ è®­ç»ƒæ ¡å‡†å™¨
    â†“
æŠŠæ ¡å‡†å™¨åº”ç”¨åˆ°ä½ è‡ªå·±çš„æ¨¡å‹ â†’ å¾—åˆ°æ ¡å‡†åçš„åˆ†æ•°

2. **Engineering**: A complete end-to-end pipeline from data processing through model training, generation, evaluation, to calibration â€” fully reproducible with shell scripts.
3. **Practical**: The ablation shows k=1 repeat suffices, cutting API costs by 66%. The calibrated scores have MAE under 0.3 on a 5-point scale, making them practically usable."

**ä¸­æ–‡è¦ç‚¹ï¼š**
- æ–¹æ³•è®ºåˆ›æ–°ï¼šå¤–éƒ¨é”šå®šæ ¡å‡†
- å·¥ç¨‹å®Œæ•´æ€§ï¼šç«¯åˆ°ç«¯å¯å¤ç°ç®¡çº¿
- å®ç”¨ä»·å€¼ï¼šk=1 å¤Ÿç”¨ï¼Œæˆæœ¬ä¼˜åŒ–

---

## ä¸‰ã€æŠ€æœ¯æ·±æ½œ | Technical Deep Dive

> é¢è¯•æ—¶æ ¹æ®æ•™æˆå…´è¶£é€‰æ‹©æ·±å…¥æŸä¸ªæ¨¡å—ã€‚  
> During the interview, dive deeper into whichever module the professor is interested in.

### 3.1 æ•°æ®ç®¡çº¿ | Data Pipeline

**Key Files:** `src/data/build_dataset.py`, `src/data/external_loader.py`

**What to say / è®²ä»€ä¹ˆï¼š**

| Topic è¯é¢˜ | English | ä¸­æ–‡ |
|---|---|---|
| Data source æ•°æ®æ¥æº | 5,318 patient-therapist Q&A records from PsychCentral | 5,318 æ¡ PsychCentral å¿ƒç†å’¨è¯¢å¯¹è¯ |
| Preprocessing é¢„å¤„ç† | Lowercasing, denoising, tokenization, cognitive distortion detection | å°å†™åŒ–ã€å»å™ªã€åˆ†è¯ã€è®¤çŸ¥æ‰­æ›²æ£€æµ‹ |
| Label masking æ ‡ç­¾æ©ç  | Prompt tokens set to `-100`; loss computed only on therapist response | Prompt tokens è®¾ä¸º -100ï¼Œloss åªç®—åœ¨æ²»ç–—å¸ˆå›å¤ä¸Š |
| Data split æ•°æ®åˆ’åˆ† | 80/10/10 (train/val/test) | 80/10/10 |
| External loader å¤–éƒ¨åŠ è½½ | Supports EPITOME, generic CSV/JSONL; auto-normalizes to 1-5 scale | æ”¯æŒ EPITOME/é€šç”¨æ ¼å¼ï¼Œè‡ªåŠ¨å½’ä¸€åŒ–åˆ° 1-5 |

**Design decisions to mention / å¯æçš„è®¾è®¡å†³ç­–ï¼š**

- **English:** "Why label masking? To prevent the model from simply learning to copy user input. The loss is only computed on the therapist's response tokens."
- **ä¸­æ–‡ï¼š** ä¸ºä»€ä¹ˆç”¨ label masking â†’ é˜²æ­¢æ¨¡å‹å­¦å¤åˆ¶ user è¾“å…¥

- **English:** "Why external data for calibration anchoring? Using your own annotations to calibrate your own judge creates circularity bias. External public datasets provide an independent, unbiased anchor."
- **ä¸­æ–‡ï¼š** ä¸ºä»€ä¹ˆç”¨å¤–éƒ¨æ•°æ® â†’ æ¶ˆé™¤"è‡ªå·±æ ‡æ³¨è‡ªå·±è¯„"çš„åå·®

---

### 3.2 æ¨¡å‹æ¶æ„ | Model Architecture: Chain-of-Empathy

**Key File:** `src/models/empathy_chain.py`

**Architecture (å¯ä»¥åœ¨ç™½æ¿ä¸Šç”» / draw on whiteboard):**

```
Input Hidden States
    â†“ mean pooling â†’ sentence-level representation (B, H)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 1: Scenario Understanding             â”‚  Linear + ReLU
â”‚  Stage 2: Emotion Recognition                â”‚  Linear + ReLU
â”‚  Stage 3: Cause Inference                    â”‚  Linear + ReLU
â”‚  Stage 4: Goal Setting                       â”‚  Linear + ReLU
â”‚  Stage 5: Response Planning                  â”‚  Linear (no activation)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Emotion-Scenario Fusion Layer:
    concat(emotion_rep, scenario_rep) â†’ Linear(2H, H) + ReLU
    â†“
Residual Connection: response_rep + fused_rep
    â†“
Broadcast-add to GPT-2 hidden states â†’ lm_head â†’ logits
```

**Key design points / å…³é”®è®¾è®¡ç‚¹ï¼š**

| Question é¢è¯•å®˜å¯èƒ½é—® | Answer å›ç­” |
|---|---|
| Why 5 stages? ä¸ºä»€ä¹ˆ5é˜¶æ®µï¼Ÿ | "Inspired by CBT (Cognitive Behavioral Therapy) â€” mirrors how humans develop empathetic responses: understand context â†’ recognize emotion â†’ infer cause â†’ set goal â†’ formulate response." æ¨¡æ‹Ÿ CBT è®¤çŸ¥è¡Œä¸ºç–—æ³•ä¸­äººç±»äº§ç”Ÿå…±æƒ…çš„è®¤çŸ¥è¿‡ç¨‹ |
| Why additive fusion, not cross-attention? ä¸ºä»€ä¹ˆåŠ æ€§èåˆï¼Ÿ | "At GPT-2 scale (124M params), additive fusion is parameter-efficient and converges faster. Cross-attention would add significant overhead for minimal gain at this scale." åœ¨ 124M è§„æ¨¡ä¸‹ï¼ŒåŠ æ€§èåˆå‚æ•°å°‘ã€æ”¶æ•›å¿« |
| Why no activation in Stage 5? ç¬¬5é˜¶æ®µä¸ºä»€ä¹ˆæ²¡æ¿€æ´»å‡½æ•°ï¼Ÿ | "The final stage needs to preserve both positive and negative activations for maximum representational capacity before fusion." ä¿ç•™æ­£è´Ÿå€¼ä¿¡æ¯ |
| Initialization? åˆå§‹åŒ–ï¼Ÿ | "Xavier Uniform for all custom layers â€” ensures stable gradients in the chain." Xavier Uniformï¼Œä¿è¯æ¢¯åº¦ç¨³å®š |

**Bonus point / é¢è¯•åŠ åˆ†ç‚¹ï¼š**

> **English:** "I want to be upfront: this model's absolute performance is limited â€” GPT-2 at 124M parameters scores only 1-2 out of 5 on empathy dimensions, which is expected for such a small model on complex therapeutic dialogue. But its value is as an **ablation control**: same data, same training loop, the only variable is the presence of the empathy reasoning chain. This lets us validate that the Judge can discriminate between models."

> **ä¸­æ–‡ï¼š** æ¨¡å‹æœ¬èº«åˆ†æ•°å¾ˆä½ï¼ˆGPT-2 å¤ªå°ï¼‰ï¼Œä½†å®ƒçš„ä»·å€¼åœ¨äºä½œä¸ºæ¶ˆèå¯¹ç…§ï¼ŒéªŒè¯ Judge çš„åˆ¤åˆ«èƒ½åŠ›ã€‚

---

### 3.3 LLM-as-a-Judge è¯„ä¼°ç®¡é“ | LLM Judge Pipeline

**Key Files:** `src/eval/llm_judge.py`, `src/eval/rubric.py`

**Pipeline (å¯ä»¥ç”»æµç¨‹å›¾ / draw this as a flowchart):**

```
rubric.py â†’ rubric_to_text() â†’ Render rubric as Markdown
    â†“
build_judge_messages() â†’ System prompt + User message
    â†“
judge_one() â†’ API call (DeepSeek / GPT-4)
    â†“
extract_json() â†’ Robust JSON extraction (strip markdown fences, regex match)
    â†“
validate_judge_output() â†’ Validate dimensions + score range + fallback
    â†“
judge_batch() â†’ Batch processing + n_repeats=3 (stability analysis)
    â†“
save_judge_results() â†’ JSONL output with full metadata
```

**Key design points / å…³é”®è®¾è®¡ç‚¹ï¼š**

| Pattern è®¾è®¡æ¨¡å¼ | English | ä¸­æ–‡ |
|---|---|---|
| Single Source of Truth | Rubric defined once in `rubric.py`, shared by human annotators and LLM Judge | è¯„åˆ†æ ‡å‡†å”¯ä¸€å®šä¹‰ï¼Œäººå·¥å’Œ LLM å…±ç”¨ |
| Strategy Pattern | `api_fn` parameter decouples API backends â€” swap DeepSeek / OpenAI / local without code changes | `api_fn` è§£è€¦ API åç«¯ |
| Robust JSON Parsing | `extract_json()` handles markdown code fences, extraneous text, format anomalies | é²æ£’ JSON æå–ï¼Œå¤„ç†å„ç§ LLM è¾“å‡ºæ ¼å¼ |
| Retry with backoff | Exponential backoff + max retries for transient API failures | æŒ‡æ•°é€€é¿é‡è¯• |
| Full metadata | Each result includes timestamp, judge model, repeat index, confidence | å®Œæ•´å…ƒæ•°æ®è¿½è¸ª |

**Key numbers / å…³é”®æ•°å­—ï¼š**
- 1,800 API calls, **0 failures** | 1,800 æ¬¡è°ƒç”¨ï¼Œ0 å¤±è´¥
- Exact self-consistency: **88-100%** | ç²¾ç¡®ä¸€è‡´ç‡ 88-100%
- Near agreement (Â±1): **96-100%** | Â±1 ä¸€è‡´ç‡ 96-100%

---

### 3.4 ç»Ÿè®¡æ ¡å‡† | Statistical Calibration

**Key Files:** `src/eval/calibrate.py`, `experiments/train_external_calibrator.py`

**Core idea (ç”»è¿™ä¸ªå›¾ / draw this diagram):**

```
                   Ideal: y = x
                    â•±
 Calibrated Score  â•±
                  â•±
                 â•±  â† Isotonic Regression
                â•±     (monotone staircase mapping)
               â•±
              â•±
             â•±
            â•± â€¢ â€¢ â€¢  â† Raw judge scores (systematic bias)
           â•±
          â•±_______________
                Human Score
```

**Two calibration routes compared / åŒè·¯æ ¡å‡†å¯¹æ¯”ï¼š**

| Aspect ç»´åº¦ | Isotonic Regression ç­‰å¼ å›å½’ | Ordinal Logistic Regression æœ‰åºé€»è¾‘å›å½’ |
|---|---|---|
| Method æ–¹æ³• | Non-parametric monotone mapping éå‚æ•°å•è°ƒæ˜ å°„ | Ordered classification probability distribution æœ‰åºåˆ†ç±»æ¦‚ç‡ |
| Pros ä¼˜ç‚¹ | Assumption-free, preserves rank order æ— å‡è®¾ï¼Œä¿åº | Outputs probability distribution è¾“å‡ºæ¦‚ç‡åˆ†å¸ƒ |
| Cons ç¼ºç‚¹ | Needs sufficient samples éœ€è¦è¶³å¤Ÿæ ·æœ¬ | Needs more features & samples éœ€è¦æ›´å¤šç‰¹å¾å’Œæ ·æœ¬ |
| Result in this project æœ¬é¡¹ç›®ç»“æœ | **MAE reduced 31-63%** | Failed â€” training set too small (n=60) è¿‡æ‹Ÿåˆ |

**Calibration results / æ ¡å‡†ç»“æœï¼š**

| Dimension ç»´åº¦ | Raw MAE â†’ Cal MAE | Reduction é™å¹… | Spearman (before â†’ after) |
|---|:---:|:---:|:---:|
| Emotion Recognition æƒ…æ„Ÿè¯†åˆ« | 0.547 â†’ 0.205 | **62.8%** | 0.61 â†’ 0.58 |
| Validation & Warmth éªŒè¯æ¸©æš– | 0.544 â†’ 0.249 | **54.1%** | 0.32 â†’ 0.33 |
| Helpfulness å®ç”¨æ€§ | 0.506 â†’ 0.219 | **56.8%** | 0.76 â†’ 0.76 |
| Safety å®‰å…¨è¾¹ç•Œ | 0.425 â†’ 0.285 | **31.3%** | 0.79 â†’ 0.78 |

**Highlight phrasing for interview / é¢è¯•äº®ç‚¹è¯´æ³•ï¼š**

> **English:** "Isotonic regression cut MAE by more than half on average, and **Spearman rank correlation remained essentially unchanged** â€” meaning calibration only corrects scale bias without hurting the judge's discriminative ability. This tells us the LLM judge's **ranking is reliable**, it just has an absolute value offset."

> **ä¸­æ–‡ï¼š** æ ¡å‡†åªè°ƒäº†å°ºåº¦åå·®ï¼Œæ’åºä¸å˜ â†’ Judge çš„åˆ¤åˆ«èƒ½åŠ›æœ¬èº«æ˜¯å¯é çš„ã€‚

---

### 3.5 æ¶ˆèå®éªŒ | Ablation Studies

#### Ablation A: Repeat Sensitivity (k=1 vs k=2 vs k=3) | é‡å¤æ¬¡æ•°æ•æ„Ÿæ€§

| k | Emotion Spearman | Safety Spearman | Emotion MAE |
|---|:---:|:---:|:---:|
| 1 | 0.658 | 0.855 | 0.201 |
| 2 | 0.661 | 0.871 | 0.206 |
| 3 | 0.651 | 0.875 | 0.204 |

> **English:** "k=1 is sufficient â€” going from 1 to 3 repeats yields marginal improvement of less than 0.01 on all metrics. This means we can **cut API costs by 66%** without sacrificing calibration quality."

> **ä¸­æ–‡ï¼š** k=1 å¤Ÿç”¨ï¼Œé¢å¤–é‡å¤è¾¹é™…æ”¶ç›Š < 0.01 â†’ çœ 66% API æˆæœ¬ã€‚

#### Ablation B: Prompt Variants (default / strict / minimal) | Prompt å˜ä½“

- Tests how different system prompt styles affect score distributions
- Validates that the rubric is **robust across prompt formulations**
- æµ‹è¯•ä¸åŒ prompt é£æ ¼å¯¹è¯„åˆ†åˆ†å¸ƒçš„å½±å“ï¼ŒéªŒè¯ rubric çš„é²æ£’æ€§

---

## å››ã€å·¥ç¨‹èƒ½åŠ›å±•ç¤º | Engineering Skills to Highlight

> å¯¹ PhD é¢è¯•ï¼Œå·¥ç¨‹èƒ½åŠ›è¯´æ˜ä½ èƒ½ç‹¬ç«‹è½åœ°ç ”ç©¶ ideaã€‚  
> For PhD interviews, engineering shows you can independently implement research ideas.

### 4.1 é¡¹ç›®æ¶æ„ | Project Architecture

```
src/
â”œâ”€â”€ data/          â† Data layer (templates, dataset builder, external loader)
â”‚                    æ•°æ®å±‚ï¼ˆæ¨¡æ¿ã€æ•°æ®é›†æ„å»ºã€å¤–éƒ¨åŠ è½½å™¨ï¼‰
â”œâ”€â”€ models/        â† Model layer (baseline GPT-2, Chain-of-Empathy, unified trainer)
â”‚                    æ¨¡å‹å±‚ï¼ˆåŸºçº¿ GPT-2ã€å…±æƒ…é“¾ã€ç»Ÿä¸€è®­ç»ƒå™¨ï¼‰
â”œâ”€â”€ inference/     â† Inference layer (unified generation interface, local + API)
â”‚                    æ¨ç†å±‚ï¼ˆç»Ÿä¸€ç”Ÿæˆæ¥å£ï¼Œæœ¬åœ° + APIï¼‰
â””â”€â”€ eval/          â† Evaluation layer (rubric, llm_judge, calibrate, metrics)
                     è¯„ä¼°å±‚ï¼ˆé‡è¡¨ã€LLM è¯„å§”ã€æ ¡å‡†ã€æŒ‡æ ‡ï¼‰
                     â†‘ Core innovation lives here / æ ¸å¿ƒåˆ›æ–°åœ¨è¿™ä¸€å±‚

experiments/       â† Experiment scripts (reproducible shell + Python)
                     å®éªŒè„šæœ¬ï¼ˆå¯å¤ç°çš„ shell + Pythonï¼‰
outputs/           â† Output layer (structured JSONL + analysis reports)
                     è¾“å‡ºå±‚ï¼ˆç»“æ„åŒ– JSONL + åˆ†ææŠ¥å‘Šï¼‰
```

**Points to make / è¦ç‚¹ï¼š**

| English | ä¸­æ–‡ |
|---|---|
| Modular layered design (data â†’ model â†’ inference â†’ eval) | æ¨¡å—åŒ–åˆ†å±‚ |
| Single source of truth (`rubric.py` is the global reference) | å•ä¸€äº‹å®æ¥æº |
| Strategy pattern (`api_fn` decouples API backends) | ç­–ç•¥æ¨¡å¼è§£è€¦ |
| One-command reproducibility via shell scripts | ä¸€é”®å¤ç° |
| Complete metadata tracking (model name, seed, temperature, timestamp per output) | å®Œæ•´å…ƒæ•°æ® |

### 4.2 ä»£ç è´¨é‡äº®ç‚¹ | Code Quality Highlights

| Feature ç‰¹æ€§ | English | ä¸­æ–‡ |
|---|---|---|
| Robust JSON parsing | `extract_json()` handles markdown fences, extraneous text, format edge cases. 1,800 calls, 0 parse failures. | é²æ£’ JSON è§£æï¼Œ1800 æ¬¡ 0 å¤±è´¥ |
| Resume-from-checkpoint | `--resume` flag skips already-processed samples â€” critical for large-scale API work | æ–­ç‚¹ç»­ä¼ ï¼Œå¤§è§„æ¨¡ API ä¸æ€•ä¸­æ–­ |
| Label masking | Prompt tokens masked with `-100` â€” standard NLP fine-tuning practice | æ ‡å‡† NLP è®­ç»ƒå®è·µ |
| Xavier initialization | Custom modules use proper weight init for gradient stability | åˆç†æƒé‡åˆå§‹åŒ– |
| Bootstrap CI | Calibration results come with 95% confidence intervals (1,000 bootstrap iterations) | æ ¡å‡†ç»“æœå¸¦ 95% CI |

### 4.3 é‡æ„ç»éªŒ | Refactoring Experience

> **English:** "The project evolved from a prototype to production-quality code. Legacy files in the root directory used Chinese GPT-2 and monolithic scripts. I refactored everything into a modular `src/` package with unified interfaces, so the full pipeline can be reproduced with a single command."

> **ä¸­æ–‡ï¼š** ä»åŸå‹é‡æ„åˆ°ç”Ÿäº§çº§ä»£ç ï¼šæ¨¡å—åŒ–ã€ç»Ÿä¸€æ¥å£ã€ä¸€é”®å¤ç°ã€‚

| Legacy æ—§æ–‡ä»¶ | New æ–°æ–‡ä»¶ | Improvement æ”¹è¿› |
|---|---|---|
| `Chain_of_Empathy.py` | `src/models/empathy_chain.py` | Integrated into full model class é›†æˆåˆ°å®Œæ•´æ¨¡å‹ |
| `Model_Baseline.py` | `src/models/baseline_gpt2.py` | Unified interface ç»Ÿä¸€æ¥å£ |
| `Train_and_Test.py` | `src/models/train.py` | Multi-model support å¤šæ¨¡å‹æ”¯æŒ |
| Scattered scripts é›¶æ•£è„šæœ¬ | `experiments/*.py` | Structured experiment pipeline ç»“æ„åŒ–ç®¡çº¿ |

---

## äº”ã€ç ”ç©¶æ€ç»´å±•ç¤º | Research Thinking to Demonstrate

### 5.1 æ­£ç¡®å®šä½ç ”ç©¶è´¡çŒ® | Positioning the Contribution

> **ä¸è¦è¯´ "I built a better empathy chatbot"ã€‚**  
> **Do NOT say "I built a better empathy chatbot."**

**Instead, say / åº”è¯¥è¯´ï¼š**

> **English:** "This is an **evaluation framework** project, not a model project. The core contribution is: how to obtain reliable empathy scores using LLM-as-a-Judge plus statistical calibration, at **zero human annotation cost**. The three models are ablation subjects to validate the evaluation framework â€” they are not the point."

> **ä¸­æ–‡ï¼š** è¿™æ˜¯**è¯„ä¼°æ¡†æ¶**é¡¹ç›®ï¼Œä¸æ˜¯æ¨¡å‹é¡¹ç›®ã€‚æ¨¡å‹åªæ˜¯éªŒè¯è¯„ä¼°æ¡†æ¶çš„æ¶ˆèå¯¹è±¡ã€‚

### 5.2 æ–¹æ³•è®ºäº®ç‚¹ | Methodological Highlights

| Insight æ´å¯Ÿ | English | ä¸­æ–‡ |
|---|---|---|
| External vs self-anchoring å¤–éƒ¨é”šå®š vs è‡ªæˆ‘é”šå®š | "Annotating your own data and then calibrating your own judge creates circularity bias. External public datasets provide independent, reproducible anchors." | è‡ªå·±æ ‡æ³¨è‡ªå·±è¯„æœ‰å¾ªç¯åå·®ï¼Œå¤–éƒ¨å…¬å¼€æ•°æ®æ˜¯ç‹¬ç«‹é”šç‚¹ |
| Calibration, not replacement æ ¡å‡†è€Œéæ›¿ä»£ | "I'm not claiming LLM judge equals human. I'm saying the judge's **ranking is reliable** â€” it just needs scale correction via calibration." | LLM Judge æ’åºå¯é ï¼Œåªéœ€è°ƒå°ºåº¦ |
| Ablation mindset æ¶ˆèæ€ç»´ | "The 3 models aren't about finding the best model. They're about validating that the judge can discriminate quality differences. The repeat ablation proves k=1 suffices, saving 66% cost." | 3 ä¸ªæ¨¡å‹æ˜¯ä¸ºäº†éªŒè¯ Judgeï¼Œk=1 å¤Ÿç”¨çœ 66% æˆæœ¬ |

### 5.3 ä¸»åŠ¨é¢å¯¹å±€é™ | Proactively Address Limitations

> é¢è¯•ä¸­**ä¸»åŠ¨æå‡ºå±€é™**æ¯”è¢«é—®åˆ°æ›´åŠ åˆ†ã€‚  
> **Volunteering** limitations is more impressive than being caught off guard.

| Limitation å±€é™ | Honest Assessment è¯šå®è¯„ä¼° | Future Work æœªæ¥æ–¹å‘ |
|---|---|---|
| Small model scale æ¨¡å‹è§„æ¨¡å° | "GPT-2 at 124M only scores 1-2/5 on empathy â€” expected for this scale." GPT-2 124M åˆ†æ•°ä½æ˜¯é¢„æœŸå†…çš„ | Research goal is the evaluation framework, not the model ç ”ç©¶ç›®æ ‡æ˜¯è¯„ä¼°æ¡†æ¶ |
| Small calibration set æ ¡å‡†æ ·æœ¬å°‘ | "n=60 caused ordinal regression to overfit completely." n=60 è®© Ordinal è¿‡æ‹Ÿåˆ | Need larger external datasets éœ€è¦æ›´å¤§å¤–éƒ¨æ•°æ®é›† |
| Validation dimension éªŒè¯ç»´åº¦éš¾ | "Spearman only 0.32 â€” lowest among dimensions." | May need finer-grained rubric anchors å¯èƒ½éœ€è¦æ›´ç²¾ç»†çš„ rubric |
| Single judge model å•ä¸€ Judge | "Only used DeepSeek Chat." åªç”¨äº† DeepSeek | Extend to cross-judge validation (GPT-4, Claude) |
| Domain specificity é¢†åŸŸç‰¹å®š | "Mental health counseling â€” generalizability untested." åªæµ‹äº†å¿ƒç†å’¨è¯¢ | Extend to customer service, education å¯æ‰©å±•åˆ°å®¢æœ/æ•™è‚² |

---

## å…­ã€é¢è¯•é«˜é¢‘é—®é¢˜ | Frequently Asked Interview Questions

> æ¯ä¸ªé—®é¢˜ç»™å‡º **è‹±æ–‡å£è¯­ç‰ˆå›ç­”**ï¼ˆé¢è¯•æ—¶ç›´æ¥ç”¨ï¼‰+ ä¸­æ–‡ç†è§£æ³¨é‡Šã€‚  
> Each question provides an **English spoken answer** (use directly) + Chinese notes.

---

### Q1: "Why not just use BLEU/ROUGE?"

> **English:** "BLEU and ROUGE measure lexical overlap with reference responses, but empathy is a semantic property. For example, 'I understand how you feel' and 'Your feelings are completely valid to me' express the same empathy, but BLEU would score near zero. My own data confirms this: the fine-tuned model has a BLEU of only 0.016, but the LLM judge rates its empathy significantly higher than vanilla GPT-2. This dimension simply isn't captured by n-gram overlap metrics."

> **ä¸­æ–‡æ³¨é‡Šï¼š** BLEU è¡¡é‡è¯åŒ¹é…ï¼Œä½†å…±æƒ…æ˜¯è¯­ä¹‰å±æ€§ã€‚æ•°æ®è¯å® Finetuned BLEU åªæœ‰ 0.016ï¼Œä½† Judge è¯„åˆ†æ˜¾è‘—æ›´é«˜ã€‚

---

### Q2: "Is LLM-as-a-Judge reliable? Doesn't it hallucinate?"

> **English:** "Great question â€” that's exactly why I built the multi-repeat and calibration pipeline. Empirically, the judge shows near-agreement rates of 96-100% across 3 independent repeats, which is actually higher than typical human inter-rater agreement on subjective tasks. But there is a systematic scale bias, which is why I apply isotonic regression calibration. After calibration, MAE drops by 31-63%, but rank correlation stays essentially unchanged â€” meaning the judge's **discriminative ability is reliable**, it just needs scale correction."

> **ä¸­æ–‡æ³¨é‡Šï¼š** Judge è‡ªä¸€è‡´ç‡ 96-100%ï¼Œæ¯”äººç±»æ ‡æ³¨è€…éƒ½é«˜ã€‚ä½†æœ‰ç³»ç»Ÿåå·® â†’ æ ¡å‡†ä¿®æ­£å°ºåº¦ï¼Œæ’åºä¸å˜ â†’ åˆ¤åˆ«èƒ½åŠ›å¯é ã€‚

---

### Q3: "Why isotonic regression? Why not something more sophisticated?"

> **English:** "Three reasons:
> 1. **Non-parametric** â€” it makes no assumption about the functional form between judge and human scores.
> 2. **Order-preserving** â€” it guarantees that the calibrated ranking is identical to the original ranking, which is critical for evaluation.
> 3. **Sample-efficient** â€” I only had 60 training samples. I actually tried ordinal logistic regression as well, and it completely overfitted. Isotonic regression is robust to small samples.
> 
> It's a principled engineering decision: choose the simplest method that works given the constraints."

> **ä¸­æ–‡æ³¨é‡Šï¼š** ä¸‰ä¸ªç†ç”±ï¼šæ— å‡è®¾ã€ä¿åºã€å¯¹å°æ ·æœ¬é²æ£’ã€‚Ordinal åœ¨ n=60 ä¸Šè¿‡æ‹Ÿåˆäº†ã€‚å·¥ç¨‹åŸåˆ™ï¼šçº¦æŸä¸‹é€‰æœ€ç®€æ–¹æ¡ˆã€‚

---

### Q4: "Chain-of-Empathy performs worse than the baseline?"

> **English:** "On the surface, yes â€” Empathy Chain scores 1.28 overall versus 1.33 for fine-tuned baseline. But both scores are extremely low â€” 1-2 out of 5 â€” because GPT-2 at 124M parameters simply doesn't have enough capacity for complex therapeutic dialogue. The difference is within the confidence interval.

> The correct interpretation is three-fold: First, GPT-2 scale is insufficient for this task. Second, the Chain-of-Empathy architecture needs to be validated on larger models â€” 7B+ â€” to see its true benefit. Third, and most importantly for this project, **the model comparison validates that the judge can discriminate** â€” vanilla scores 1.0, fine-tuned scores 1.33. That's the purpose of the models in this framework."

> **ä¸­æ–‡æ³¨é‡Šï¼š** ä¸¤è€…ç»å¯¹åˆ†æ•°éƒ½å¾ˆä½ï¼ˆGPT-2 å¤ªå°ï¼‰ï¼Œå·®å¼‚åœ¨ CI å†…ã€‚é‡è¦çš„æ˜¯ Judge èƒ½åŒºåˆ† vanilla (1.0) vs finetuned (1.33)ã€‚

---

### Q5: "What about domain shift between external calibration data and your own data?"

> **English:** "Excellent question. This is a real risk. My mitigation strategy has three layers:
> 1. The rubric uses **domain-general empathy dimensions** â€” emotion recognition and validation are universal, not domain-specific.
> 2. The calibrator learns the **judge's systematic bias pattern**, not domain features. If the judge consistently overrates emotion recognition, that bias transfers across domains.
> 3. For future work, a small amount of in-domain human annotation could enable domain adaptation â€” even 50-100 samples would significantly reduce domain shift. Or we can select public datasets closer to our domain."

> **ä¸­æ–‡æ³¨é‡Šï¼š** ä¸‰å±‚åº”å¯¹ï¼šé€šç”¨ç»´åº¦ã€å­¦çš„æ˜¯ Judge åå·®æ¨¡å¼ã€æœªæ¥å¯å°‘é‡ in-domain æ ‡æ³¨åš adaptationã€‚

---

### Q6: "What would you do with more time/resources?"

> **English:** "Three things, in priority order:
> 1. **Cross-judge validation** â€” run the same rubric with DeepSeek, GPT-4, and Claude, then analyze whether different judges have different bias patterns. This would tell us whether the calibration is judge-specific or generalizable.
> 2. **Scale up the model** â€” validate Chain-of-Empathy on LLaMA-7B or 13B to see if the architecture truly helps at sufficient scale.
> 3. **Interactive user study** â€” build a web interface where real users chat with different models, use the judge pipeline for real-time quality monitoring, and correlate automated scores with user satisfaction. This would close the loop between automated evaluation and actual user experience."

> **ä¸­æ–‡æ³¨é‡Šï¼š** ä¸‰ä»¶äº‹ï¼šCross-Judge éªŒè¯ã€æ›´å¤§æ¨¡å‹éªŒè¯ã€çœŸäººäº¤äº’ç”¨æˆ·ç ”ç©¶ã€‚

---

### Q7: "What's your publication plan?"

> **English:** "The contribution supports a workshop paper or short paper. Target venues include the EMNLP/ACL Workshop on NLP for Mental Health, or AIES â€” AI Ethics and Society. The paper structure would be: problem definition â†’ rubric design â†’ judge reliability analysis â†’ external-anchored calibration â†’ ablation studies â†’ practical guidelines for using LLM judges in evaluation."

> **ä¸­æ–‡æ³¨é‡Šï¼š** å¯ä»¥æŠ• EMNLP/ACL mental health workshop æˆ– AIESã€‚

---

### Q8: "What was the biggest challenge?"

> **English:** "Two challenges stand out:
> 1. **Robust LLM output parsing** â€” different API versions return different formats: sometimes markdown code fences, sometimes extra explanatory text. I wrote an `extract_json()` function with regex fallback that handles all edge cases. 1,800 calls with zero parse failures.
> 2. **Calibration with limited data** â€” with only 60 training samples, ordinal logistic regression completely overfitted. This forced a principled engineering decision: sometimes the simplest method â€” isotonic regression â€” is the right choice when you're data-constrained. That's a lesson I internalized through this project."

> **ä¸­æ–‡æ³¨é‡Šï¼š** ä¸¤ä¸ªæŒ‘æˆ˜ï¼šLLM è¾“å‡ºè§£æï¼ˆ1800 æ¬¡ 0 å¤±è´¥ï¼‰+ å°æ ·æœ¬æ ¡å‡†ï¼ˆæœ€ç®€æ–¹æ¡ˆåè€Œæœ€å¥½ï¼‰ã€‚

---

### Q9: "How does this relate to Professor X's research?" (é‡èº«å®šåˆ¶ Customize this)

> **å‡†å¤‡ç­–ç•¥ / Preparation Strategyï¼š**
> 1. Read professor's 2-3 most recent papers æå‰è¯»æ•™æˆæœ€è¿‘ 2-3 ç¯‡è®ºæ–‡
> 2. Find intersection points æ‰¾äº¤å‰ç‚¹, for example:
>    - If professor does **NLG evaluation**: "My calibration approach could extend to their evaluation framework..."
>    - If **AI safety**: "The safety dimension in my rubric directly connects to..."
>    - If **human-AI interaction**: "My judge pipeline could serve as a real-time quality monitor in..."
>    - If **computational social science**: "The empathy measurement framework could be applied to..."
>    - If **mental health NLP**: "My evaluation framework directly addresses the core challenge of measuring therapeutic quality..."

---

### Q10: "Can you walk me through the code?"

> **English:** "Sure. The project has a clean layered architecture:
> - `src/data/` handles data loading and preprocessing â€” 5,318 dialogues, with label masking so loss is only computed on therapist responses.
> - `src/models/` has two model classes: a thin GPT-2 wrapper and the Chain-of-Empathy model with 5-stage reasoning.
> - `src/eval/` is where the core contribution lives â€” rubric definitions, the LLM judge pipeline with structured JSON output, and the calibration module supporting isotonic and ordinal methods.
> - `experiments/` contains reproducible experiment scripts â€” each one is independently runnable and idempotent.
> 
> Would you like me to dive into any specific module?"

> **ä¸­æ–‡æ³¨é‡Šï¼š** ç®€æ´æè¿°åˆ†å±‚ï¼Œç„¶åè®©æ•™æˆé€‰æ‹©æ·±å…¥å“ªä¸€å±‚ã€‚ä¸»åŠ¨å¼•å¯¼å¯¹è¯ã€‚

---

## ä¸ƒã€æ¼”ç¤º Demo æµç¨‹ | Demo Walkthrough

### æœ‰ç”µè„‘ / å±å¹•å…±äº« | With Computer / Screen Share

#### Step 1: Show Project Structure å±•ç¤ºé¡¹ç›®ç»“æ„ (1min)
```bash
tree src/ -L 2   # Show clean module layout
```

#### Step 2: Show Data Samples å±•ç¤ºæ•°æ® (1min)
```bash
# Show one training sample å±•ç¤ºä¸€æ¡è®­ç»ƒæ•°æ®
head -1 data/formatted_Psych_data.jsonl | python -m json.tool

# Show one generation output å±•ç¤ºä¸€æ¡ç”Ÿæˆç»“æœ
head -1 outputs/generations/empathy_chain.jsonl | python -m json.tool
```

#### Step 3: Show Judge Results å±•ç¤ºè¯„åˆ†ç»“æœ (2min)
```bash
# Score distribution åˆ†æ•°åˆ†å¸ƒ
python experiments/quick_score_dist.py

# Or full analysis å®Œæ•´åˆ†æ
python experiments/analyse_judge_results.py 2>/dev/null | head -60
```

#### Step 4: Show Calibration å±•ç¤ºæ ¡å‡† (2min)
```bash
cat outputs/analysis/calibration_report_paper.md
```

#### Step 5: Show Ablation å±•ç¤ºæ¶ˆè (1min)
```bash
cat outputs/analysis/ablation_repeats.md
```

### æ— è®¾å¤‡ / å¹»ç¯ç‰‡ | Without Computer / Slides Only

å»ºè®® **5-7 é¡µ** slides / Recommend **5-7 slides**:

| Slide | English Content | ä¸­æ–‡å†…å®¹ |
|---|---|---|
| 1 | Title + one-line summary: "Automated Evaluation Framework for Empathetic Dialogue" | æ ‡é¢˜ + ä¸€å¥è¯ |
| 2 | Problem: BLEU fails â†’ Human costly â†’ Need LLM Judge | é—®é¢˜ï¼šBLEU ä¸å¤Ÿ â†’ äººå·¥å¤ªè´µ â†’ LLM Judge |
| 3 | System architecture diagram: Data â†’ Models â†’ Generation â†’ Judge â†’ Calibration | æ¶æ„å›¾ |
| 4 | Chain-of-Empathy: 5-stage reasoning chain + fusion | 5 é˜¶æ®µæ¨ç†é“¾ + èåˆæœºåˆ¶ |
| 5 | Calibration results table: MAE reduced 31-63%, Spearman preserved | æ ¡å‡†ç»“æœ |
| 6 | Ablation: k=1 suffices â†’ 66% cost reduction | æ¶ˆèç»“è®º |
| 7 | Contributions + 3 future directions | è´¡çŒ® + æœªæ¥æ–¹å‘ |

---

## å…«ã€æŒ‰é¢è¯•åœºæ™¯è°ƒæ•´é‡å¿ƒ | Adjusting Focus by Interview Type

### ğŸ“ PhD Interview / PhD é¢è¯•

**Emphasize / é‡ç‚¹å±•ç¤ºï¼š**
- Research motivation and problem formulation ç ”ç©¶åŠ¨æœºä¸é—®é¢˜å®šä¹‰
- Methodological novelty (external anchored calibration, ablation design) æ–¹æ³•è®ºåˆ›æ–°
- Statistical rigor (bootstrap CI, IAA analysis, GO/NO-GO gates) ç»Ÿè®¡ä¸¥è°¨æ€§
- Paper-writing ability (rubric design, annotation protocol) è®ºæ–‡å†™ä½œèƒ½åŠ›
- Future research directions and how they connect to advisor's work æœªæ¥æ–¹å‘ä¸å¯¼å¸ˆæ–¹å‘çš„äº¤é›†
- Intellectual honesty about limitations è¯šå®é¢å¯¹å±€é™æ€§

**De-emphasize / å°‘è®²ï¼š**
- Engineering details (code structure, refactoring history) å·¥ç¨‹ç»†èŠ‚

### ğŸ”¬ RA (Research Assistant) Interview / RA é¢è¯•

**Emphasize / é‡ç‚¹å±•ç¤ºï¼š**
- Independent research execution ability ç‹¬ç«‹è½åœ°èƒ½åŠ›
- Full-stack skills: model training + API integration + statistical analysis å…¨æ ˆèƒ½åŠ›
- Reproducibility and documentation quality å¯å¤ç°æ€§ä¸æ–‡æ¡£è´¨é‡
- Ability to handle real-world constraints (small data, API costs) å®é™…çº¦æŸå¤„ç†
- Self-directed problem solving è‡ªä¸»è§£å†³é—®é¢˜

**De-emphasize / å°‘è®²ï¼š**
- Deep theoretical motivation è¿‡æ·±çš„ç†è®ºåŠ¨æœº

### ğŸ’» Industry ML / NLP Engineer Interview / å·¥ä¸šç•Œé¢è¯•

**Emphasize / é‡ç‚¹å±•ç¤ºï¼š**
- End-to-end system design ç«¯åˆ°ç«¯ç³»ç»Ÿ
- Code quality (modular, resume-from-checkpoint, robust parsing, metadata) ä»£ç è´¨é‡
- Cost consciousness (ablation proves k=1 â†’ 66% cost reduction) æˆæœ¬æ„è¯†
- Prototype-to-production refactoring experience é‡æ„ç»éªŒ
- API integration experience (DeepSeek, OpenAI) API é›†æˆ

**De-emphasize / å°‘è®²ï¼š**
- Mathematical details of statistical methods ç»Ÿè®¡æ–¹æ³•çš„æ•°å­¦ç»†èŠ‚

### ğŸ¤– AI Safety / AI Ethics å²—ä½

**Emphasize / é‡ç‚¹å±•ç¤ºï¼š**
- Safety dimension design philosophy (boundary awareness, professional referral) Safety ç»´åº¦
- LLM Judge reliability and bias analysis Judge åå·®åˆ†æ
- Fairness implications of calibration (unbiased anchoring) æ ¡å‡†çš„å…¬å¹³æ€§
- HAI evaluation methodology HAI è¯„ä¼°æ–¹æ³•è®º

---

## ä¹ã€ç®€å† Bullet Points | Resume Bullet Points

> æ ¹æ®ç›®æ ‡å²—ä½é€‰ä¸€ç»„ã€‚  
> Pick the set that matches your target position.

### General / é€šç”¨ç‰ˆ
- Designed and implemented an end-to-end evaluation framework for empathetic dialogue systems, using LLM-as-a-Judge with statistical calibration (isotonic regression), reducing score MAE by 31-63% against human ratings with zero manual annotation cost
- Built a 5-stage Chain-of-Empathy neural module for GPT-2, modeled after CBT cognitive processes, with additive fusion into transformer hidden states
- Executed 1,800 LLM API evaluations with 0 errors, achieving 96-100% self-consistency rate across 3 independent repeats

### Research-Oriented / ç ”ç©¶ç‰ˆ
- Proposed external human-anchored calibration for LLM-as-a-Judge, training isotonic/ordinal calibrators on public datasets (EPITOME) and transferring to own model outputs; achieved MAE reduction of 31-63% with preserved rank correlation (Spearman 0.32-0.79)
- Designed 4-dimension empathy evaluation rubric (emotion recognition, validation & warmth, helpfulness, safety) as single source of truth for both human annotators and LLM judge, with inter-annotator agreement protocol (weighted Îº, Krippendorff Î±)
- Conducted ablation studies on judge repeat sensitivity (k=1/2/3) and prompt variants, demonstrating k=1 sufficiency for 66% API cost reduction without calibration quality degradation

### Engineering-Oriented / å·¥ç¨‹ç‰ˆ
- Architected modular NLP evaluation pipeline (Python, PyTorch, HuggingFace): data processing â†’ model training â†’ batch inference â†’ LLM judge â†’ statistical calibration, with shell scripts for full reproducibility
- Implemented robust LLM output parsing with regex-based JSON extraction, exponential backoff retry, and resume-from-checkpoint, handling 1,800 API calls with zero failures
- Refactored legacy monolithic codebase into layered architecture (data/models/inference/eval), unified training interface supporting multiple model types, and standardized JSONL output with complete metadata tracking

---

## é™„å½•ï¼šå…³é”®æ•°å­—é€ŸæŸ¥è¡¨ | Appendix: Key Numbers Cheat Sheet

> é¢è¯•å‰è¿‡ä¸€éï¼Œç¡®ä¿è‹±æ–‡èƒ½è„±å£è€Œå‡ºã€‚  
> Review before interview â€” make sure you can say these numbers fluently in English.

| Item é¡¹ç›® | Value æ•°å€¼ | How to say it è‹±æ–‡å£è¯­ |
|---|---|---|
| Training data è®­ç»ƒæ•°æ® | 5,318 dialogues | "About fifty-three hundred mental health counseling dialogues" |
| Model size æ¨¡å‹å‚æ•° | GPT-2 124M | "GPT-2 with 124 million parameters" |
| Test samples æµ‹è¯•æ ·æœ¬ | 200 per model | "Two hundred test samples per model" |
| Number of models æ¨¡å‹æ•° | 3 | "Three contrastive models: vanilla, fine-tuned, and empathy chain" |
| Total API calls API æ€»è°ƒç”¨ | 1,800 | "Eighteen hundred API calls â€” two hundred times three models times three repeats" |
| API errors é”™è¯¯æ•° | 0 | "Zero failures" |
| Scoring dimensions è¯„åˆ†ç»´åº¦ | 4 | "Four dimensions: emotion, validation, helpfulness, and safety" |
| Likert scale é‡è¡¨ | 1-5 | "One-to-five Likert scale" |
| Judge exact agreement ç²¾ç¡®ä¸€è‡´ | 88-100% | "Eighty-eight to one hundred percent exact agreement" |
| Judge near agreement (Â±1) | 96-100% | "Ninety-six to one hundred percent near agreement" |
| Isotonic MAE reduction é™å¹… | 31-63% | "Thirty-one to sixty-three percent MAE reduction" |
| Post-calibration MAE æ ¡å‡†å | 0.20-0.29 | "Point two to point two nine on a five-point scale" |
| Optimal k (repeats) æœ€ä¼˜é‡å¤æ•° | k=1 | "k equals one is sufficient" |
| Bootstrap iterations | 1,000 | "One thousand bootstrap iterations" |
| Calibration train set æ ¡å‡†è®­ç»ƒé›† | 60 | "Sixty training samples" |
| Calibration test set æ ¡å‡†æµ‹è¯•é›† | 20 | "Twenty test samples" |
| Best BLEU (finetuned) | 0.016 | "Point zero one six" |
| Best ROUGE-1 (finetuned) | 0.297 | "Point two nine seven" |
| Vanilla judge overall | 1.00 | "One point zero" |
| Finetuned judge overall | 1.33 | "One point three three" |
| Empathy Chain judge overall | 1.28 | "One point two eight" |

---

## é¢è¯•å‰ Checklist âœ… | Pre-Interview Checklist

- [ ] èƒ½æµåˆ©è¯´å‡º 30s Elevator Pitch (English) | Can deliver 30s pitch fluently in English
- [ ] èƒ½ç”» Chain-of-Empathy æ¶æ„å›¾ | Can draw Chain-of-Empathy architecture on whiteboard
- [ ] èƒ½ç”» Calibration æ ¸å¿ƒæ¦‚å¿µå›¾ | Can draw calibration concept diagram
- [ ] èƒ½è„±å£è€Œå‡º 5 ä¸ªå…³é”®æ•°å­— (English) | Can cite 5 key numbers from memory in English
- [ ] èƒ½å›ç­” "why not BLEU" in English | Can answer "why not BLEU" fluently
- [ ] èƒ½å›ç­” "is LLM judge reliable" in English | Can answer "is LLM judge reliable" fluently
- [ ] èƒ½ä¸»åŠ¨è¯´å‡º 3 ä¸ªå±€é™æ€§ in English | Can proactively state 3 limitations in English
- [ ] èƒ½è¯´å‡º 3 ä¸ªæœªæ¥æ–¹å‘ in English | Can state 3 future directions in English
- [ ] å·²é˜…è¯»ç›®æ ‡æ•™æˆæœ€è¿‘ 2-3 ç¯‡è®ºæ–‡ | Have read target professor's 2-3 recent papers
- [ ] å‡†å¤‡äº†é¡¹ç›®ä¸æ•™æˆæ–¹å‘çš„äº¤å‰ç‚¹ | Prepared intersection points with advisor's research
- [ ] æµ‹è¯•è¿‡ Demo å‘½ä»¤èƒ½å¦è¿è¡Œ | Tested that demo commands run successfully
- [ ] å‡†å¤‡äº† 5-7 é¡µ backup slides (English) | Prepared 5-7 backup slides in English
